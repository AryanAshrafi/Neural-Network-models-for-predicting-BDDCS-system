{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AryanAshrafi/Neural-Network-models-for-predicting-BDDCS-system/blob/main/ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xo53GuG0Ic_U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZZcFvSTIkmo"
      },
      "outputs": [],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKKkzrAIJFal"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('B.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjvpC4rNQ6AV"
      },
      "outputs": [],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk-1J5-ENVfk"
      },
      "outputs": [],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTBY6StvNu_0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_train = X[:-119]\n",
        "y_train = y[:-119]\n",
        "X_test = X[-119:]\n",
        "y_test = y[-119:]\n",
        "\n",
        "\n",
        "# Define custom metric for validation accuracy\n",
        "def val_accuracy(y_true, y_pred):\n",
        "    y_pred = tf.round(y_pred)\n",
        "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "    correct = tf.equal(y_true, y_pred)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
        "    return accuracy\n",
        "\n",
        "# Create a sequential model\n",
        "ann = Sequential()\n",
        "\n",
        "# Add layers to the model with dropout regularization\n",
        "ann.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ann.add(Dropout(0.6))  # Add dropout layer with dropout rate of 0.2\n",
        "ann.add(Dense(64, activation='relu'))\n",
        "ann.add(Dropout(0.4))  # Add dropout layer with dropout rate of 0.2\n",
        "ann.add(Dense(32, activation='relu'))\n",
        "ann.add(Dropout(0.2))  # Add dropout layer with dropout rate of 0.2\n",
        "ann.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with custom validation accuracy metric\n",
        "ann.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=500)\n",
        "\n",
        "# Train the model\n",
        "history = ann.fit(X_train, y_train, epochs=600, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the training and validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Check for overfitting\n",
        "if len(history.history['val_loss']) > 10 and all(val_loss > history.history['val_loss'][-1] for val_loss in history.history['val_loss'][-10:-1]):\n",
        "    print(\"Overfitting detected!\")\n",
        "else:\n",
        "    print(\"No overfitting detected.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_TwZJj-OXtO",
        "outputId": "1289989c-6350-427b-b31b-2d4511b9cffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert predicted labels to binary (0 or 1)\n",
        "y_pred = ann.predict(X_test)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Create a DataFrame with predicted labels and original values\n",
        "prediction_df = pd.DataFrame({'Predictions': y_pred_binary.reshape(-1), 'Original Values': y_test.reshape(-1)})\n",
        "\n",
        "# Save the DataFrame as an Excel file\n",
        "prediction_df.to_excel('predictions.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXaYgRv-D2bl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Convert predicted probabilities to binary labels using a threshold\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_binary)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Compute and print the accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "print(\"Accuracy Score: {:.2f}%\".format(accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5SPtjTUKQFb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Convert predicted probabilities to binary labels using a threshold\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_binary)\n",
        "\n",
        "# Plot confusion matrix using seaborn heatmap\n",
        "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# Compute and print accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "print(\"Accuracy Score: {:.2f}%\".format(accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNOKLtmpR3OZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Predict labels for the training data\n",
        "y_train_pred = ann.predict(X_train)\n",
        "y_train_pred = (y_train_pred > 0.5) # Convert probabilities to binary predictions\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_train = confusion_matrix(y_train, y_train_pred)\n",
        "print(\"Confusion Matrix for Training Data:\")\n",
        "print(cm_train)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
        "print(\"Accuracy Score for Training Data:\", accuracy_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XULryUKR78s"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate confusion matrix for training data\n",
        "cm_train = confusion_matrix(y_train, y_train_pred)\n",
        "\n",
        "# Create a heatmap of the confusion matrix\n",
        "sns.heatmap(cm_train, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix for Training Data\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZCwf7esU0Kr"
      },
      "outputs": [],
      "source": [
        "y_train_pred = ann.predict(X_train)\n",
        "y_train_pred = (y_train_pred > 0.5).astype(int)  # Convert predicted probabilities to binary labels\n",
        "\n",
        "# Create a DataFrame to store original values and predictions\n",
        "train_data_predictions = pd.DataFrame({'Original Values': y_train.flatten(), 'Predictions': y_train_pred.flatten()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRlC2NGUWmVU"
      },
      "outputs": [],
      "source": [
        "# Set display options to show all rows and columns without truncation\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Print the table with original values and predictions\n",
        "print(\"Table with Original Values and Predictions for Training Data:\")\n",
        "print(train_data_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJinN1rJ1y6m"
      },
      "outputs": [],
      "source": [
        "# Set display options to show all rows and columns without truncation\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Print the table with original values and predictions\n",
        "print(\"Table with Original Values and Predictions for Training Data:\")\n",
        "print(train_data_predictions)\n",
        "\n",
        "# Convert train_data_predictions to an Excel file\n",
        "train_data_predictions.to_excel('train_data_predictions.xlsx', index=False)\n",
        "print(\"train_data_predictions has been saved to train_data_predictions.xlsx\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFUU84V+dhX+dWqBI5VZN7",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}